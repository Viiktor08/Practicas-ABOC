# PrÃ¡ctica 2: OptimizaciÃ³n con Restricciones (ADALINA LASSO)

Este repositorio contiene la implementaciÃ³n de **ADALINA con regularizaciÃ³n â„“1 (LASSO)** para resolver un problema de regresiÃ³n lineal. El modelo fue optimizado utilizando el **mÃ©todo de Gradiente Proyectado**, el cual impone restricciones sobre la norma â„“1 del vector de pesos para fomentar la selecciÃ³n automÃ¡tica de caracterÃ­sticas y evitar el sobreajuste.

## ğŸ“Œ DescripciÃ³n

Se ha trabajado sobre el mismo conjunto de datos que en la PrÃ¡ctica 1 (**Boston Housing**), aplicando regularizaciÃ³n â„“1. Se implementÃ³ el algoritmo de **Gradiente Proyectado** que realiza:

- MinimizaciÃ³n de la funciÃ³n de pÃ©rdida regularizada:  
  min_{w} (1/2) * ||Xw - y||^2 + Î» * ||w||_1
- ProyecciÃ³n del gradiente en el conjunto factible para respetar la restricciÃ³n â„“1.
- SelecciÃ³n dinÃ¡mica del tamaÃ±o de paso mediante backtracking.

## ğŸ“ Estructura del Proyecto

```
â”œâ”€â”€ ADALINALassoGradienteProyectado.py # ImplementaciÃ³n del Gradiente Proyectado con LASSO
â”œâ”€â”€ hou_all.csv                        # Dataset de viviendas (Boston Housing)
â”œâ”€â”€ P2_ABOC.pdf                        # Informe con resultados y anÃ¡lisis
```

## âš™ï¸ Requisitos

- Python 3.x
- LibrerÃ­as:
  - numpy
  - pandas

InstalaciÃ³n de dependencias:
```bash
pip install numpy pandas
```

## ğŸ§ª Instrucciones de EjecuciÃ³n

1. El dataset `hou_all.csv` es cargado y preprocesado dentro del script (eliminaciÃ³n del bias y normalizaciÃ³n).
2. El valor de **Î»** usado por defecto es **100**.
3. Ejecutar el script:
```bash
python ADALINALassoGradienteProyectado.py
```

## ğŸ“Š Resultados

- NÃºmero de iteraciones hasta convergencia (Î» = 100): **14**
- Algunos coeficientes se anulan completamente â†’ se logra **sparsity**
- ComparaciÃ³n de los valores reales y predichos:

| Vivienda | Real | Predicho |
|----------|------|----------|
| 1        | 24.0 | 26.19    |
| 2        | 21.6 | 26.18    |
| 3        | 34.7 | 31.09    |
| 4        | 33.4 | 28.72    |
| 5        | 36.2 | 27.34    |

### ğŸ” AnÃ¡lisis del efecto de Î»

| Î»       | DescripciÃ³n                                         |
|---------|-----------------------------------------------------|
| 10      | Poca penalizaciÃ³n, muchos coeficientes â‰  0          |
| 50      | Aparecen ceros, mejora generalizaciÃ³n               |
| 100     | Buen equilibrio entre ajuste y simplicidad          |
| 200     | Modelo muy penalizado, riesgo de **subajuste**      |

> Se muestra una grÃ¡fica en el informe del nÃºmero de caracterÃ­sticas seleccionadas segÃºn Î».

## ğŸ§  Conclusiones

- El **Gradiente Proyectado** permite abordar eficazmente problemas con restricciones â„“1.
- La regularizaciÃ³n LASSO introduce **sparsity**, lo que ayuda a seleccionar automÃ¡ticamente caracterÃ­sticas relevantes.
- La elecciÃ³n de **Î»** es crÃ­tica para equilibrar **precisiÃ³n** y **complejidad** del modelo.

## ğŸ‘¤ Autor

- VÃ­ctor Tirado  
- victortiradoarregui@uma.es  
- Universidad de MÃ¡laga â€” Algoritmos de BÃºsqueda y OptimizaciÃ³n Computacional

## ğŸ“„ Licencia

Este proyecto es solo con fines acadÃ©micos.
